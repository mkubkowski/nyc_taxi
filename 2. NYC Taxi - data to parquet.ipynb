{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a611bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae8e0d",
   "metadata": {},
   "source": [
    "# Converting the data to parquet for efficiency and not to use too much disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7569fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_in = \"G:/dane_python/nyc_taxi/\"\n",
    "folder_out = \"G:/dane_python/nyc_taxi_parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01efd2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in = listdir(folder_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc1850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_2020-01.csv',\n",
       " 'yellow_tripdata_2020-02.csv',\n",
       " 'yellow_tripdata_2020-03.csv',\n",
       " 'yellow_tripdata_2020-04.csv',\n",
       " 'yellow_tripdata_2020-05.csv',\n",
       " 'yellow_tripdata_2020-06.csv',\n",
       " 'yellow_tripdata_2020-07.csv',\n",
       " 'yellow_tripdata_2020-08.csv',\n",
       " 'yellow_tripdata_2020-09.csv',\n",
       " 'yellow_tripdata_2020-10.csv',\n",
       " 'yellow_tripdata_2020-11.csv',\n",
       " 'yellow_tripdata_2020-12.csv',\n",
       " 'yellow_tripdata_2021-01.csv',\n",
       " 'yellow_tripdata_2021-02.csv',\n",
       " 'yellow_tripdata_2021-03.csv',\n",
       " 'yellow_tripdata_2021-04.csv',\n",
       " 'yellow_tripdata_2021-05.csv',\n",
       " 'yellow_tripdata_2021-06.csv',\n",
       " 'yellow_tripdata_2021-07.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea1e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {\"VendorID\": \"Int64\", \n",
    "              \"tpep_pickup_datetime\": \"str\",\n",
    "             \"tpep_dropoff_datetime\": \"str\",\n",
    "             \"passenger_count\": \"Int64\",\n",
    "             \"trip_distance\": \"float64\",\n",
    "             \"RatecodeID\": \"Int64\",\n",
    "             \"store_and_fwd_flag\": \"str\",\n",
    "             \"PULocationID\": \"Int64\",\n",
    "             \"DOLocationID\": \"Int64\",\n",
    "              \"payment_type\": \"Int64\",\n",
    "              \"fare_amount\": \"float64\",\n",
    "              \"extra\":\"float64\",\n",
    "              \"mta_tax\":\"float64\",\n",
    "              \"tip_amount\":\"float64\",\n",
    "              \"tolls_amount\":\"float64\",\n",
    "              \"improvement_surcharge\":\"float64\",\n",
    "              \"total_amount\":\"float64\",\n",
    "              \"congestion_surcharge\":\"float64\",\n",
    "             }\n",
    "\n",
    "date_cols = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db46839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_loc = \"G:/dane_python/nyc_taxi_other/taxi_zones_lat_long.parquet\"\n",
    "geo_data = pd.read_parquet(geo_data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb130e",
   "metadata": {},
   "source": [
    "## Calculation of travel distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b185f3",
   "metadata": {},
   "source": [
    "Here I calculate haversine distance, based on two latitudes and longitudes (more here: https://en.wikipedia.org/wiki/Haversine_formula). Additionally, I calculate $L_1$ distance between pickup and dropoff points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7759de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfba1ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file yellow_tripdata_2020-01.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-01.csv to parquet\n",
      "Reading file yellow_tripdata_2020-02.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-02.csv to parquet\n",
      "Reading file yellow_tripdata_2020-03.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-03.csv to parquet\n",
      "Reading file yellow_tripdata_2020-04.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-04.csv to parquet\n",
      "Reading file yellow_tripdata_2020-05.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-05.csv to parquet\n",
      "Reading file yellow_tripdata_2020-06.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-06.csv to parquet\n",
      "Reading file yellow_tripdata_2020-07.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-07.csv to parquet\n",
      "Reading file yellow_tripdata_2020-08.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-08.csv to parquet\n",
      "Reading file yellow_tripdata_2020-09.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-09.csv to parquet\n",
      "Reading file yellow_tripdata_2020-10.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-10.csv to parquet\n",
      "Reading file yellow_tripdata_2020-11.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-11.csv to parquet\n",
      "Reading file yellow_tripdata_2020-12.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2020-12.csv to parquet\n",
      "Reading file yellow_tripdata_2021-01.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-01.csv to parquet\n",
      "Reading file yellow_tripdata_2021-02.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-02.csv to parquet\n",
      "Reading file yellow_tripdata_2021-03.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-03.csv to parquet\n",
      "Reading file yellow_tripdata_2021-04.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-04.csv to parquet\n",
      "Reading file yellow_tripdata_2021-05.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-05.csv to parquet\n",
      "Reading file yellow_tripdata_2021-06.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-06.csv to parquet\n",
      "Reading file yellow_tripdata_2021-07.csv\n",
      "Merging...\n",
      "Calculating distances...\n",
      "Converting file yellow_tripdata_2021-07.csv to parquet\n"
     ]
    }
   ],
   "source": [
    "for file in files_in:\n",
    "    print('Reading file '+ file)\n",
    "    df = pd.read_csv(folder_in + file,dtype = data_types,parse_dates = date_cols)\n",
    "    \n",
    "    print('Merging...')\n",
    "    df1 = df.merge(geo_data,how='left',left_on=\"PULocationID\",right_on=\"LocationID\",suffixes=['','_PU'])\\\n",
    "        .merge(geo_data,how='left',left_on=\"DOLocationID\",right_on=\"LocationID\",suffixes=['','_DO'])\n",
    "    df1 = df1.rename(columns={x : x + '_PU' for x in geo_data.columns})\n",
    "    \n",
    "    print('Calculating distances...')\n",
    "    df1['distance_L2'] = haversine_array(df1['latitude_PU'].values, df1['longitude_PU'].values, df1['latitude_DO'].values, df1['longitude_DO'].values)\n",
    "    df1['distance_L1'] = dummy_manhattan_distance(df1['latitude_PU'].values, df1['longitude_PU'].values, df1['latitude_DO'].values, df1['longitude_DO'].values)\n",
    "    \n",
    "    print('Converting file '+ file + ' to parquet')\n",
    "    df1.to_parquet(folder_out + file.split('.')[0] + '.parquet', compression= None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
